***** Task 3 Performance File *****

Multi Layer Perceptron
Classification task: emotion

Confusion Matrix
[[  761    33     2     1     6     1     0     3     0     0     0     0
      0     2     0    65     0    23    78     0  1127    27     0     0
      0     0     0     5]
 [   30   302     1     3     0     1     0     2     0     0     2     1
      0     0     0     7     0    18     9     0   851     4     0     0
      0     0     1     1]
 [    4    15    88     5     0     1     0     4     0     0     2    12
      0     0     0     3     0     0     8     0   914     2     0     0
      0     0     4     0]
 [   14    26    26    10     0     1     0     2     0     0     9    10
      0     0     2     9     0     2     9     0  1552     3     0     0
      0     0    12     1]
 [   77    15     6     2    28     2     0     3     0     0     9     3
      0     0     0    30     0     4    45     0  1983    17     0     0
      0     0     2     0]
 [   20     1     0     0     0    11     0     0     0     0     2     1
      0     0     0    25     0     5     9     0   565    21     0     0
      0     7     2     0]
 [    8     9     2     0     1     0     0    12     0     0     6     3
      0     0     1     5     0     0     5     0   909     0     0     0
      0     1     1     2]
 [   12    10     2     2     2     1     1    50     0     0     1     1
      0     0     0     8     0     0     5     0  1042     5     0     0
      0     0     0     1]
 [   12     3     0     0     1     0     0     2     1     0     1     0
      0     0     0    13     0     3    19     0   359    24     0     0
      0     0     1     0]
 [    7     9     4     2     0     0     0     0     0     1     4     1
      0     0     1     3     0     2     5     0   898     5     0     0
      0     1    27     0]
 [   10    19     3     3     2     1     0     0     0     0    31     6
      0     0     0     9     0     1     6     0  1435     3     0     0
      0     0     8     0]
 [    5    15    23     1     1     0     0     0     0     0     5    25
      0     0     1     1     0     0     5     0   495     0     0     0
      0     0     8     0]
 [    4     5     0     3     0     0     0     0     0     0     0     2
      0     0     1     2     0     0     3     0   276     0     0     0
      0     1     6     0]
 [   43     5     1     1     1     0     0     2     0     0     0     0
      0     4     0    11     0    24    16     0   480     6     0     0
      0     0     1     2]
 [    2     1     1     0     0     0     0     0     0     0     0     8
      0     0    11     0     0     0     0     0   284     3     0     0
      0     0     6     1]
 [   39     4     0     0     1     5     0     0     0     0     0     0
      0     0     0   919     0    16    12     0   400    10     0     0
      0     1     2     0]
 [    0     0     2     1     0     0     0     0     0     0     0     0
      0     0     0     4     0     0     0     0    48     0     0     0
      0     0     3     0]
 [   60    44     1     0     1     0     0     1     0     0     0     0
      0     6     0    31     0    68    50     0   532    17     0     0
      0     0     3     0]
 [   38    17     1     0     0     1     0     0     0     0     0     0
      0     1     0     8     0     3   486     0   445     3     0     0
      0     1     0     0]
 [    0     1     1     0     0     0     0     0     0     0     0     0
      0     0     1     1     0     0     0     0   173     0     0     0
      0     0     9     1]
 [  199   108    50     5    18    19     1    45     0     0    42    14
      0     0     5    90     0    32    82     0 10274    52     0     0
      0     3    25     3]
 [   36     4     0     0     0     6     0     0     0     0     2     0
      0     0     0    22     0    12     9     0   724    98     0     0
      0     0     1     0]
 [   14     1     1     0     0     1     0     0     0     0     0     0
      0     0     0     9     0     1     1     0   126     3     0     0
      0     0     0     0]
 [    9    11     1     0     0     0     0     0     0     0     3     0
      0     0     0     4     0     1     6     0   936     0     0     0
      0     0     1     0]
 [   10     2     0     0     0     1     0     0     0     0     0     0
      0     0     0    10     0     3     3     0   124     2     0     0
      0     0     1     0]
 [    1     7     1     0     0     0     0     0     0     0     1     0
      0     0     0    15     0     0     0     0   217     2     0     0
      0    18    10     0]
 [    8    13     5     4     0     1     0     2     0     0     3     1
      0     0     0     9     0     1    13     0   649     3     0     0
      0    17    66     0]
 [   31    17     2     1     0     2     0     3     0     0     2     0
      0     0     0     3     0     5     1     0   611     3     0     0
      0     0     0    10]]

Classification Report
              precision    recall  f1-score   support

           0       0.52      0.36      0.42      2134
           1       0.43      0.24      0.31      1233
           2       0.39      0.08      0.14      1062
           3       0.23      0.01      0.01      1688
           4       0.45      0.01      0.02      2226
           5       0.20      0.02      0.03       669
           6       0.00      0.00      0.00       965
           7       0.38      0.04      0.08      1143
           8       1.00      0.00      0.00       439
           9       1.00      0.00      0.00       970
          10       0.25      0.02      0.04      1537
          11       0.28      0.04      0.07       585
          12       0.00      0.00      0.00       303
          13       0.31      0.01      0.01       597
          14       0.48      0.03      0.06       317
          15       0.70      0.65      0.67      1409
          16       0.00      0.00      0.00        58
          17       0.30      0.08      0.13       814
          18       0.55      0.48      0.51      1004
          19       0.00      0.00      0.00       187
          20       0.36      0.93      0.52     11067
          21       0.31      0.11      0.16       914
          22       0.00      0.00      0.00       157
          23       0.00      0.00      0.00       972
          24       0.00      0.00      0.00       156
          25       0.36      0.07      0.11       272
          26       0.33      0.08      0.13       795
          27       0.37      0.01      0.03       691

    accuracy                           0.39     34364
   macro avg       0.33      0.12      0.12     34364
weighted avg       0.38      0.39      0.27     34364


Multi Layer Perceptron
Classification task: sentiment

Confusion Matrix
[[   0  183 2381 1207]
 [   0  777 4481 2516]
 [   0  354 7343 3370]
 [   0  236 3713 7803]]

Classification Report
              precision    recall  f1-score   support

           0       0.00      0.00      0.00      3771
           1       0.50      0.10      0.17      7774
           2       0.41      0.66      0.51     11067
           3       0.52      0.66      0.59     11752

    accuracy                           0.46     34364
   macro avg       0.36      0.36      0.31     34364
weighted avg       0.42      0.46      0.40     34364


Top Multi Layer Perceptron
Hyper parameters used:{'activation': 'relu', 'hidden_layer_sizes': (30, 50), 'solver': 'sgd'}
Classification task: emotion

Confusion Matrix
[[  813    21     0     0     0     0     0     0     0     0     0     0
      0     0     0    91     0     0    84     0  1125     0     0     0
      0     0     0     0]
 [   64   124     4     0     0     0     0     0     0     0     0     0
      0     0     0    10     0     0    24     0  1007     0     0     0
      0     0     0     0]
 [    4    15    31     0     0     0     0     0     0     0     2     0
      0     0     0     3     0     0     5     0  1002     0     0     0
      0     0     0     0]
 [   15    28    16     0     0     0     0     0     0     0     3     0
      0     0     0     8     0     0    12     0  1606     0     0     0
      0     0     0     0]
 [  102    13     1     0     0     0     0     0     0     0     5     0
      0     0     0    55     0     0    40     0  2010     0     0     0
      0     0     0     0]
 [   24     3     0     0     0     0     0     0     0     0     0     0
      0     0     0    56     0     0     9     0   577     0     0     0
      0     0     0     0]
 [   11     2     2     0     0     0     0     0     0     0     2     0
      0     0     0     3     0     0     5     0   940     0     0     0
      0     0     0     0]
 [   14     2     2     0     0     0     0     0     0     0     0     0
      0     0     0     8     0     0     4     0  1113     0     0     0
      0     0     0     0]
 [   16     1     0     0     0     0     0     0     0     0     0     0
      0     0     0    39     0     0    18     0   365     0     0     0
      0     0     0     0]
 [   13    18     2     0     2     0     0     0     0     0     6     0
      0     0     0     6     0     0     5     0   918     0     0     0
      0     0     0     0]
 [   19    12     3     0     1     0     0     0     0     0    10     0
      0     0     0    10     0     0     7     0  1475     0     0     0
      0     0     0     0]
 [    6    17    10     0     0     0     0     0     0     0     2     0
      0     0     0     1     0     0     6     0   543     0     0     0
      0     0     0     0]
 [    5     7     5     0     0     0     0     0     0     0     1     0
      0     0     0     1     0     0     3     0   281     0     0     0
      0     0     0     0]
 [   63     8     0     0     0     0     0     0     0     0     0     0
      0     0     0    27     0     0    19     0   480     0     0     0
      0     0     0     0]
 [    3     5     0     0     0     0     0     0     0     0     2     0
      0     0     0     0     0     0     1     0   306     0     0     0
      0     0     0     0]
 [   68     2     0     0     0     0     0     0     0     0     1     0
      0     0     0   884     0     0    11     0   443     0     0     0
      0     0     0     0]
 [    1     1     0     0     0     0     0     0     0     0     0     0
      0     0     0     3     0     0     0     0    53     0     0     0
      0     0     0     0]
 [  117    17     0     0     0     0     0     0     0     0     0     0
      0     0     0    70     0     1    50     0   559     0     0     0
      0     0     0     0]
 [   89    11     0     0     0     0     0     0     0     0     1     0
      0     0     0    19     0     0   433     0   451     0     0     0
      0     0     0     0]
 [    0     2     0     0     0     0     0     0     0     0     0     0
      0     0     0     1     0     0     0     0   184     0     0     0
      0     0     0     0]
 [  276    51    31     0     2     0     0     0     0     0     9     0
      0     0     0   139     0     0    63     0 10496     0     0     0
      0     0     0     0]
 [   44     1     0     0     0     0     0     0     0     0     3     0
      0     0     0   114     0     0     7     0   745     0     0     0
      0     0     0     0]
 [   17     0     0     0     0     0     0     0     0     0     0     0
      0     0     0    15     0     0     3     0   122     0     0     0
      0     0     0     0]
 [   14     4     1     0     0     0     0     0     0     0     0     0
      0     0     0     5     0     0     8     0   940     0     0     0
      0     0     0     0]
 [   12     1     0     0     0     0     0     0     0     0     0     0
      0     0     0     9     0     0     3     0   131     0     0     0
      0     0     0     0]
 [    1    12     0     0     1     0     0     0     0     0     2     0
      0     0     0     8     0     0     0     0   248     0     0     0
      0     0     0     0]
 [   14    32     6     0     5     0     0     0     0     0     9     0
      0     0     0    10     0     0    14     0   705     0     0     0
      0     0     0     0]
 [   32    19     0     0     1     0     0     0     0     0     1     0
      0     0     0     7     0     0     5     0   626     0     0     0
      0     0     0     0]]

Classification Report
              precision    recall  f1-score   support

           0       0.44      0.38      0.41      2134
           1       0.29      0.10      0.15      1233
           2       0.27      0.03      0.05      1062
           3       0.00      0.00      0.00      1688
           4       0.00      0.00      0.00      2226
           5       0.00      0.00      0.00       669
           6       0.00      0.00      0.00       965
           7       0.00      0.00      0.00      1143
           8       0.00      0.00      0.00       439
           9       0.00      0.00      0.00       970
          10       0.17      0.01      0.01      1537
          11       0.00      0.00      0.00       585
          12       0.00      0.00      0.00       303
          13       0.00      0.00      0.00       597
          14       0.00      0.00      0.00       317
          15       0.55      0.63      0.59      1409
          16       0.00      0.00      0.00        58
          17       1.00      0.00      0.00       814
          18       0.52      0.43      0.47      1004
          19       0.00      0.00      0.00       187
          20       0.36      0.95      0.52     11067
          21       0.00      0.00      0.00       914
          22       0.00      0.00      0.00       157
          23       0.00      0.00      0.00       972
          24       0.00      0.00      0.00       156
          25       0.00      0.00      0.00       272
          26       0.00      0.00      0.00       795
          27       0.00      0.00      0.00       691

    accuracy                           0.37     34364
   macro avg       0.13      0.09      0.08     34364
weighted avg       0.23      0.37      0.24     34364


Top Multi Layer Perceptron
Hyper parameters used:{'activation': 'relu', 'hidden_layer_sizes': (30, 50), 'solver': 'sgd'}
Classification task: sentiment

Confusion Matrix
[[ 291  662 1856  962]
 [ 117 3532 2595 1530]
 [ 252 1896 5955 2964]
 [  99 1112 2581 7960]]

Classification Report
              precision    recall  f1-score   support

           0       0.38      0.08      0.13      3771
           1       0.49      0.45      0.47      7774
           2       0.46      0.54      0.50     11067
           3       0.59      0.68      0.63     11752

    accuracy                           0.52     34364
   macro avg       0.48      0.44      0.43     34364
weighted avg       0.50      0.52      0.50     34364


Top Multi Layer Perceptron (best)
Hyper parameters used:{'activation': 'identity', 'hidden_layer_sizes': (30, 50), 'solver': 'adam'}
Classification task: emotion

Confusion Matrix
[[ 809   20    5    8   31    4    1    8    8    1    6    2    1   20
     2   62    0   34   72    0  987   24    7    2    0    0    1   19]
 [  35  342    4    8    1    2    0    4    0    0    4    2    0    3
     1   11    0   24    7    0  765    4    0    1    0    2    4    9]
 [   5   15  148   47    1    8    2    5    1    1    3   15    0    2
     6    4    0    1    3    0  787    2    0    0    0    0    3    3]
 [  19   28   48   57    7    2    1   11    2    5   18   16    1    4
     2    4    0    6    8    0 1416    4    0    1    0    1   17   10]
 [  76   22    8    9  102    7    7    3   12    3   19    7    0    6
     4   21    2   10   43    2 1821   20    0    3    0    2   13    4]
 [  15    3    2    3    3   52    1    3    5    0    2    1    0    0
     1   24    0    7    7    0  498   25    0    0    0    6   10    1]
 [   8   10    3    6   11    3   29   44    0    2    9    2    0    1
     1    6    0    1    4    0  811    1    0    4    0    0    4    5]
 [  11    6    4    4    4    2    9  119    2    0    3    2    1    1
     2    6    3    3    5    0  938    5    0    0    0    0    4    9]
 [   6    3    0    1    3    0    0    4   69    0    1    0    0    0
     1    7    0    0   14    0  311   18    0    0    0    0    1    0]
 [   7    5   10   10    3    3    2    3    2   10    8    8    1    1
     7    5    0    5    5    0  820    7    0    1    0    3   37    7]
 [   9   17    9   19   13    3    5    2    2    4   77    7    3    0
     6   11    0    4    4    0 1311    6    0    5    0    4   13    3]
 [   3    5   29   19    2    1    0    0    2    0    6   53    1    2
     4    1    0    0    2    0  439    2    0    0    0    0   11    3]
 [   2    2    1    5    1    0    0    0    0    0    1    3   19    0
     2    1    0    0    2    0  253    1    0    3    0    1    4    2]
 [  37   12    4    3    5    0    1    7    4    0    0    0    0   46
     1   12    1   18   12    0  414    8    0    0    0    0    2   10]
 [   3    1    4    0    1    2    0    1    0    2    1    7    1    0
    59    0    1    0    0    2  221    4    0    1    0    0    4    2]
 [  57    3    1    0    5   12    0    2    2    0    1    0    0    6
     0  933    0   20    8    0  341    9    0    0    0    4    5    0]
 [   0    0    2    0    0    0    0    0    0    0    0    0    0    0
     1    2    1    0    0    0   43    0    0    0    0    1    8    0]
 [  67   49    1    1    5    6    0    1    3    0    0    0    0   18
     0   26    1  125   37    0  461    4    1    0    1    0    4    3]
 [  56   13    0    1    4    3    1    1    2    0    0    0    0    4
     0    8    0   10  465    0  431    3    0    0    0    1    0    1]
 [   0    0    2    2    1    0    0    1    0    1    1    0    0    2
    10    1    0    1    0    6  150    2    0    0    0    0    6    1]
 [ 227  118   96   62   86   53   29  121   34   11   99   36    3   49
    20   96   14   64   83    4 9570   57    6   13    6    8   73   29]
 [  34    4    0    0    6   15    1    2   12    0    6    0    0    2
     0   24    0    6    6    0  644  146    0    1    0    0    2    3]
 [  20    0    1    0    1    0    0    0    1    1    0    1    0    0
     0    4    0    7    1    0  111    2    6    0    0    0    1    0]
 [  10   10    3    4    8    0    1    4    3    1    8    1    0    3
     1    6    1    0    4    0  883    2    0    7    0    0    4    8]
 [   9    1    0    0    3    3    0    0    0    2    1    0    0    0
     0    7    0    9    2    0  113    1    0    1    0    0    4    0]
 [   0    5    1    1    2    1    0    0    2    0    0    1    0    0
     0    6    0    0    0    1  172    1    0    0    0   46   33    0]
 [   5    7    7    8    3    1    1    2    3   11    4    4    1    0
     2    4    3    3    6    1  535    4    0    2    0   32  146    0]
 [  20   12    5    4    2    2    2   11    1    0    4    3    0    9
     2    3    1    4    1    0  530    3    0    1    0    0    2   69]]

Classification Report
              precision    recall  f1-score   support

           0       0.52      0.38      0.44      2134
           1       0.48      0.28      0.35      1233
           2       0.37      0.14      0.20      1062
           3       0.20      0.03      0.06      1688
           4       0.32      0.05      0.08      2226
           5       0.28      0.08      0.12       669
           6       0.31      0.03      0.05       965
           7       0.33      0.10      0.16      1143
           8       0.40      0.16      0.23       439
           9       0.18      0.01      0.02       970
          10       0.27      0.05      0.08      1537
          11       0.31      0.09      0.14       585
          12       0.59      0.06      0.11       303
          13       0.26      0.08      0.12       597
          14       0.44      0.19      0.26       317
          15       0.72      0.66      0.69      1409
          16       0.04      0.02      0.02        58
          17       0.35      0.15      0.21       814
          18       0.58      0.46      0.52      1004
          19       0.38      0.03      0.06       187
          20       0.37      0.86      0.52     11067
          21       0.40      0.16      0.23       914
          22       0.30      0.04      0.07       157
          23       0.15      0.01      0.01       972
          24       0.00      0.00      0.00       156
          25       0.41      0.17      0.24       272
          26       0.35      0.18      0.24       795
          27       0.34      0.10      0.15       691

    accuracy                           0.39     34364
   macro avg       0.35      0.16      0.19     34364
weighted avg       0.37      0.39      0.31     34364


Top Multi Layer Perceptron (best)
Hyper parameters used:{'activation': 'logistic', 'hidden_layer_sizes': (30, 50), 'solver': 'adam'}
Classification task: sentiment

Confusion Matrix
[[ 543  576 2044  608]
 [ 185 3362 3258  969]
 [ 362 1601 7201 1903]
 [ 191 1148 3629 6784]]

Classification Report
              precision    recall  f1-score   support

           0       0.42      0.14      0.21      3771
           1       0.50      0.43      0.46      7774
           2       0.45      0.65      0.53     11067
           3       0.66      0.58      0.62     11752

    accuracy                           0.52     34364
   macro avg       0.51      0.45      0.46     34364
weighted avg       0.53      0.52      0.51     34364



Multi Layer Perceptron using glove-twitter-100
Hyper parameters used:{'activation': 'identity', 'alpha': 0.0001, 'batch_size': 'auto', 'beta_1': 0.9, 'beta_2': 0.999, 'early_stopping': False, 'epsilon': 1e-08, 'hidden_layer_sizes': (30, 50), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'max_fun': 15000, 'max_iter': 200, 'momentum': 0.9, 'n_iter_no_change': 10, 'nesterovs_momentum': True, 'power_t': 0.5, 'random_state': None, 'shuffle': True, 'solver': 'adam', 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': True, 'warm_start': False}
Classification task: emotion

Confusion Matrix
[[ 655   11    5    3    7    7    1    1    2    3    1    2    2    4
     1   89    0    6   58    0 1255   15    1    0    0    1    1    3]
 [  43  149    3    5    4    0    2    5    0    0    4    1    0    1
     1   20    0   12   12    0  963    2    0    0    0    0    6    0]
 [  14    3   50   45    1    3    0    9    0    4    6    9    0    1
     4   10    0    0    6    0  894    0    0    0    0    0    1    2]
 [  18   10   26   32    2    3    2    2    1    9   12   11    1    1
     5    8    0    2    8    0 1525    1    0    0    0    1    6    2]
 [  79   11    3    4   39    7    0    3    2    2   19    2    1    1
     0   56    1    3   31    1 1945    8    0    1    0    2    1    4]
 [  15    0    1    2    0   17    0    0    1    0    2    1    0    0
     0   55    0    0    3    0  549   11    0    1    0    6    5    0]
 [  10    5    1    4    1    0   10   36    0    1    5    1    0    0
     1    6    0    0    2    0  880    1    0    0    0    0    0    1]
 [   9    1    0    5    0    0    4  106    3    0    3    1    1    0
     0    7    0    1    2    0  992    3    0    0    0    0    1    4]
 [  14    3    0    1    1    1    1    3   25    0    0    0    0    0
     0    9    0    2    6    0  367    6    0    0    0    0    0    0]
 [  19    2    3    7    0    0    0    0    0    9    7    4    0    0
     3    2    0    2    8    0  882    3    0    0    0    2   15    2]
 [  19    5    3   14    8    0    2    1    0    5   45   11    1    0
     0   16    0    3    5    0 1387    3    0    1    0    2    6    0]
 [   8    6    8   11    0    0    0    0    0    3    2   40    1    0
     3    1    0    0    4    0  494    2    0    0    0    0    2    0]
 [   4    2    0    4    0    0    0    1    0    1    1    0    3    0
     0    1    0    0    1    0  283    0    0    0    0    2    0    0]
 [  38    1    3    1    1    2    1    1    0    2    1    0    0   15
     1   18    0   12    7    0  488    3    0    0    0    0    0    2]
 [   1    0    1    0    0    2    0    0    0    3    1    3    0    2
    34    0    0    1    0    0  266    1    0    0    0    0    1    1]
 [  48    5    2    1    3    8    0    1    1    0    2    0    0    0
     0  544    0   10   13    0  761    6    0    0    0    2    2    0]
 [   2    0    1    0    0    0    0    1    0    1    0    0    0    0
     1    1    0    0    1    0   47    0    0    0    0    0    3    0]
 [  63   16    0    2    2    7    2    0    1    0    0    1    0    8
     0   57    1   42   27    0  576    6    0    0    1    0    2    0]
 [  50    5    1    2    1    2    0    0    1    0    2    0    0    1
     0   20    0    5  296    0  615    1    0    0    0    1    1    0]
 [   1    0    0    2    0    0    2    0    0    1    2    0    1    2
     1    1    0    0    0    8  164    0    0    0    0    0    2    0]
 [ 206   69   25   52   18   36   20  121   10   13   67   28    6   15
    14  212    2   35   75    4 9953   27    1    3    0    7   32   16]
 [  34    2    1    1    3   11    1    2    6    0    1    0    0    0
     1   48    0    3    6    0  740   51    0    0    0    0    2    1]
 [  12    0    0    0    0    1    0    0    0    2    0    0    0    0
     0   15    0    0    0    0  122    3    1    0    0    0    1    0]
 [   8    1    0    1    3    0    2    2    0    2    2    2    0    0
     0    7    1    1    5    0  926    3    0    2    0    2    0    2]
 [  10    1    0    0    2    3    0    1    0    1    1    0    0    0
     0   11    0    3    1    0  121    0    0    0    0    0    1    0]
 [   2    0    0    1    0    0    0    0    1    2    2    0    1    0
     0   13    0    1    0    0  225    1    0    0    0   21    2    0]
 [  15    2    3    3    0    4    0    1    0    6    6    2    0    0
     8    9    1    3    7    1  615    4    0    1    0   27   75    2]
 [  21    3    4    4    1    0    1   10    1    1    8    2    0    1
     0    9    0    3    2    0  601    1    0    2    0    0    1   15]]

Classification Report
              precision    recall  f1-score   support

           0       0.46      0.31      0.37      2134
           1       0.48      0.12      0.19      1233
           2       0.35      0.05      0.08      1062
           3       0.15      0.02      0.03      1688
           4       0.40      0.02      0.03      2226
           5       0.15      0.03      0.04       669
           6       0.20      0.01      0.02       965
           7       0.35      0.09      0.15      1143
           8       0.45      0.06      0.10       439
           9       0.13      0.01      0.02       970
          10       0.22      0.03      0.05      1537
          11       0.33      0.07      0.11       585
          12       0.17      0.01      0.02       303
          13       0.29      0.03      0.05       597
          14       0.44      0.11      0.17       317
          15       0.44      0.39      0.41      1409
          16       0.00      0.00      0.00        58
          17       0.28      0.05      0.09       814
          18       0.51      0.29      0.37      1004
          19       0.57      0.04      0.08       187
          20       0.35      0.90      0.50     11067
          21       0.31      0.06      0.09       914
          22       0.33      0.01      0.01       157
          23       0.18      0.00      0.00       972
          24       0.00      0.00      0.00       156
          25       0.28      0.08      0.12       272
          26       0.44      0.09      0.16       795
          27       0.26      0.02      0.04       691

    accuracy                           0.36     34364
   macro avg       0.30      0.10      0.12     34364
weighted avg       0.33      0.36      0.25     34364


Multi Layer Perceptron using glove-twitter-100glove-twitter-100
Hyper parameters used:{'activation': 'logistic', 'alpha': 0.0001, 'batch_size': 'auto', 'beta_1': 0.9, 'beta_2': 0.999, 'early_stopping': False, 'epsilon': 1e-08, 'hidden_layer_sizes': (30, 50), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'max_fun': 15000, 'max_iter': 200, 'momentum': 0.9, 'n_iter_no_change': 10, 'nesterovs_momentum': True, 'power_t': 0.5, 'random_state': None, 'shuffle': True, 'solver': 'adam', 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': True, 'warm_start': False}
Classification task: sentiment

Confusion Matrix
[[ 824  660 1432  855]
 [ 218 3489 2485 1582]
 [ 564 2100 5324 3079]
 [ 183 1418 2824 7327]]

Classification Report
              precision    recall  f1-score   support

           0       0.46      0.22      0.30      3771
           1       0.46      0.45      0.45      7774
           2       0.44      0.48      0.46     11067
           3       0.57      0.62      0.60     11752

    accuracy                           0.49     34364
   macro avg       0.48      0.44      0.45     34364
weighted avg       0.49      0.49      0.49     34364


Multi Layer Perceptron using fasttext-wiki-news-subwords-300
Hyper parameters used:{'activation': 'identity', 'alpha': 0.0001, 'batch_size': 'auto', 'beta_1': 0.9, 'beta_2': 0.999, 'early_stopping': False, 'epsilon': 1e-08, 'hidden_layer_sizes': (30, 50), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'max_fun': 15000, 'max_iter': 200, 'momentum': 0.9, 'n_iter_no_change': 10, 'nesterovs_momentum': True, 'power_t': 0.5, 'random_state': None, 'shuffle': True, 'solver': 'adam', 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': True, 'warm_start': False}
Classification task: emotion

Confusion Matrix
[[ 864   15    9    2   19    4    1    6    3    0    5    2    1    9
     2   32    0   25   66    0 1018   19    6    1    0    1    1   23]
 [  34  381    8    7    1    0    2    4    0    0    3    3    0    2
     1    8    0   20    9    0  738    2    0    1    0    1    2    6]
 [   7    6  175   28    1    3    2   17    0    5   10   24    0    1
     4    5    0    1    3    0  757    3    0    0    0    0    6    4]
 [  17   21   53   54    3    1    4   13    4    6   17   19    3    3
     2    8    0    8    8    0 1408    4    0    1    0    3   13   15]
 [  92   19    8    4   76    5    8    9    9    4   16    5    0    2
     3   19    2   14   37    0 1844   25    0    4    0    2   12    7]
 [  20    4    2    0    3   43    1    5    4    0    2    1    0    0
     0   19    0    4    8    0  507   32    0    0    0    9    5    0]
 [   7    8    1    6    6    0   64  112    0    0    4    1    0    0
     0    3    0    0    6    0  737    0    0    1    0    0    5    4]
 [  12    4    7    4    1    0   26  260    1    0    1    1    1    1
     2    4    1    1    5    0  797    5    0    0    0    0    1    8]
 [   8    4    2    0    1    1    2    4   71    0    1    0    0    0
     1    2    0    0   15    0  304   19    0    0    0    2    2    0]
 [  13    6   12   10    2    1    1    1    4   18   13    7    3    0
     3    5    0    3    6    0  805    7    0    1    0    7   34    8]
 [  14   14   10   13    9    3    8   10    4    7   86   12    1    0
     5   10    0    3    3    0 1287   11    0    2    0    5   15    5]
 [   6    4   24   13    3    0    0    3    0    1    4   68    0    0
     5    3    0    0    5    0  437    1    0    0    0    1    6    1]
 [   1    3    2    3    0    0    0    2    0    1    3    3   18    0
     0    1    0    0    1    0  255    1    0    2    0    2    4    1]
 [  47    5    4    0    2    0    1    9    4    1    0    0    0   34
     0   12    0   21   10    0  427    4    0    0    0    0    2   14]
 [   3    1    1    0    0    1    0    1    0    2    1    5    0    1
    63    0    0    0    0    1  226    3    0    0    0    0    7    1]
 [  68    6    0    0    2    7    1    0    2    0    0    0    0    0
     0  932    0   23    6    0  341   10    0    0    0    7    4    0]
 [   2    0    3    0    0    0    0    1    1    0    0    0    0    0
     2    2    0    0    0    0   37    0    0    0    0    1    9    0]
 [  76   57    4    1    4    4    0    0    2    0    0    0    0   18
     0   22    1  111   36    0  462    3    1    1    1    1    4    5]
 [  55   10    2    0    2    2    0    0    2    0    0    0    0    0
     0    5    0   16  440    0  464    3    0    0    0    1    0    2]
 [   0    0    2    0    0    2    1    1    0    0    1    0    0    1
     9    1    0    1    0    9  150    2    0    0    0    0    6    1]
 [ 236   98  115   43   66   47   62  248   43   13  101   41    3   27
    19   65    4   54   73    1 9502   65    3    6    1   15   71   45]
 [  34    6    0    0    5   10    1    2   18    1    6    0    0    1
     1   14    0    5    8    0  619  176    0    0    0    1    3    3]
 [  20    0    1    0    1    1    0    1    1    2    0    0    0    0
     0    0    0    6    0    0  113    2    7    0    0    0    1    1]
 [  10    9    3    2    5    1    6    4    2    0    7    2    0    1
     1    4    0    1    7    0  873    4    0   13    0    2    6    9]
 [  11    0    1    0    1    4    1    0    0    1    1    0    0    0
     0    6    0   11    1    0  112    1    0    0    0    0    4    1]
 [   0    3    2    1    0    0    1    0    2    1    1    1    2    0
     1    2    0    0    0    0  170    2    0    0    0   63   18    2]
 [   7    4    7    4    0    2    0    1    5   10    4    3    1    0
     2    3    0    3    6    0  555    5    0    2    0   37  132    2]
 [  31    7    9    5    3    1    3   15    0    0    2    1    0    6
     1    3    0    3    1    0  511    4    0    0    0    0    2   83]]

Classification Report
              precision    recall  f1-score   support

           0       0.51      0.40      0.45      2134
           1       0.55      0.31      0.40      1233
           2       0.37      0.16      0.23      1062
           3       0.27      0.03      0.06      1688
           4       0.35      0.03      0.06      2226
           5       0.30      0.06      0.11       669
           6       0.33      0.07      0.11       965
           7       0.36      0.23      0.28      1143
           8       0.39      0.16      0.23       439
           9       0.25      0.02      0.03       970
          10       0.30      0.06      0.09      1537
          11       0.34      0.12      0.17       585
          12       0.55      0.06      0.11       303
          13       0.32      0.06      0.10       597
          14       0.50      0.20      0.28       317
          15       0.78      0.66      0.72      1409
          16       0.00      0.00      0.00        58
          17       0.33      0.14      0.19       814
          18       0.58      0.44      0.50      1004
          19       0.82      0.05      0.09       187
          20       0.37      0.86      0.52     11067
          21       0.43      0.19      0.27       914
          22       0.41      0.04      0.08       157
          23       0.37      0.01      0.03       972
          24       0.00      0.00      0.00       156
          25       0.39      0.23      0.29       272
          26       0.35      0.17      0.23       795
          27       0.33      0.12      0.18       691

    accuracy                           0.40     34364
   macro avg       0.39      0.17      0.21     34364
weighted avg       0.39      0.40      0.32     34364


Multi Layer Perceptron using fasttext-wiki-news-subwords-300
Hyper parameters used:{'activation': 'identity', 'alpha': 0.0001, 'batch_size': 'auto', 'beta_1': 0.9, 'beta_2': 0.999, 'early_stopping': False, 'epsilon': 1e-08, 'hidden_layer_sizes': (30, 50), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'max_fun': 15000, 'max_iter': 200, 'momentum': 0.9, 'n_iter_no_change': 10, 'nesterovs_momentum': True, 'power_t': 0.5, 'random_state': None, 'shuffle': True, 'solver': 'adam', 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': True, 'warm_start': False}
Classification task: sentiment

Confusion Matrix
[[ 917  627 1568  659]
 [ 237 3957 2474 1106]
 [ 545 2048 6152 2322]
 [ 200 1296 2719 7537]]

Classification Report
              precision    recall  f1-score   support

           0       0.48      0.24      0.32      3771
           1       0.50      0.51      0.50      7774
           2       0.48      0.56      0.51     11067
           3       0.65      0.64      0.64     11752

    accuracy                           0.54     34364
   macro avg       0.53      0.49      0.50     34364
weighted avg       0.54      0.54      0.54     34364
